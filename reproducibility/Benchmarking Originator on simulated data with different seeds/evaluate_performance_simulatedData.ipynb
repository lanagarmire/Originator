{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e663150-fe0e-41dc-90de-d046485fead8",
   "metadata": {},
   "source": [
    "This file is used to evaluate the performance of Originator on simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5075314-f7e7-40aa-99ab-959be516e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thatchau/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# This file is used to evaluation the performance of the model using the metrics including:\n",
    "# 1) AUCROC (macro), 2) AUCROC (micro), 3) AUCPR, 4) F1 score, 5) MCC, and 6) ARI\n",
    "# Input data:\n",
    "# 1) A file containing truth labels (1st column), and predictions (2nd) columns\n",
    "\n",
    "from traceback import print_tb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d222f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input_path = \"/nfs/dcmb-lgarmire/thatchau/originator_GB_revision/results/simulatedData_seeds/\"\n",
    "\n",
    "seeds = [0, 42, 64, 123, 894]\n",
    "celltypes = [\"tcell\", \"mono\", \"b\"]\n",
    "unified_celltypes = [\"T-cell\", \"Monocyte\", \"B-cell\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2acbd28",
   "metadata": {},
   "source": [
    "##### Evaluate results (change file name manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5ad279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_predictions = \"/nfs/dcmb-lgarmire/thatchau/originator_GB_revision/results/simulatedData_seeds/b/894/prediction_TB_B-cell_TBannotation.csv\"\n",
    "df_file_predictions = pd.read_csv(path_file_predictions) \n",
    "\n",
    "list_truth_labels = (df_file_predictions.iloc[:, 6]).tolist()\n",
    "\n",
    "list_predictions = (df_file_predictions.iloc[:, 5]).tolist()\n",
    "\n",
    "list_truth_labels_one_hot = tf.keras.utils.to_categorical(list_truth_labels, num_classes=2)\n",
    "list_predictions_one_hot = tf.keras.utils.to_categorical(list_predictions, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b615ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get AUC (macro)\n",
    "auc_macro = roc_auc_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'macro')\n",
    "\n",
    "# get AUC (micro)\n",
    "auc_micro = roc_auc_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'micro')\n",
    "\n",
    "# get AUCPR\n",
    "auc_pr = average_precision_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'micro')\n",
    "\n",
    "# get F1 score\n",
    "f1 = f1_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'micro')\n",
    "\n",
    "# get MCC\n",
    "mcc = matthews_corrcoef(list_truth_labels, list_predictions)\n",
    "\n",
    "# get ARI\n",
    "ari = adjusted_rand_score(list_truth_labels, list_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00681952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_macro:  0.9983361064891847\n",
      "auc_micro:  0.9971202303815695\n",
      "auc_pr:  0.9956886386454096\n",
      "f1:  0.9971202303815695\n",
      "MCC:  0.987825640726239\n",
      "ARI:  0.9840291576953247\n"
     ]
    }
   ],
   "source": [
    "print(\"auc_macro: \", auc_macro)\n",
    "print(\"auc_micro: \", auc_micro)\n",
    "print(\"auc_pr: \", auc_pr)\n",
    "print(\"f1: \", f1)\n",
    "print(\"MCC: \", mcc)\n",
    "print(\"ARI: \", ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14950ff1",
   "metadata": {},
   "source": [
    "Calculate overall performace of cell types in the same seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "66921b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bcell_predictions = pd.read_csv(\"/nfs/dcmb-lgarmire/thatchau/originator_GB_revision/results/simulatedData_seeds/b/894/prediction_TB_B-cell_TBannotation.csv\")\n",
    "Tcell_predictions = pd.read_csv(\"/nfs/dcmb-lgarmire/thatchau/originator_GB_revision/results/simulatedData_seeds/tcell/894/prediction_TB_T-cell_TBannotation.csv\") \n",
    "mono_predictions = pd.read_csv(\"/nfs/dcmb-lgarmire/thatchau/originator_GB_revision/results/simulatedData_seeds/mono/894/prediction_TB_Monocyte_TBannotation.csv\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74513a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-110-434c2c5f48a9>:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_concat = Bcell_predictions.append(Tcell_predictions)\n",
      "<ipython-input-110-434c2c5f48a9>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_concat = df_concat.append(mono_predictions)\n"
     ]
    }
   ],
   "source": [
    "df_concat = Bcell_predictions.append(Tcell_predictions)\n",
    "df_concat = df_concat.append(mono_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f12b77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_truth_labels = (df_concat.iloc[:, 6]).tolist()\n",
    "\n",
    "list_predictions = (df_concat.iloc[:, 5]).tolist()\n",
    "\n",
    "list_truth_labels_one_hot = tf.keras.utils.to_categorical(list_truth_labels, num_classes=2)\n",
    "list_predictions_one_hot = tf.keras.utils.to_categorical(list_predictions, num_classes=2)\n",
    "\n",
    "# get AUC (macro)\n",
    "auc_macro = roc_auc_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'macro')\n",
    "\n",
    "# get AUC (micro)\n",
    "auc_micro = roc_auc_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'micro')\n",
    "\n",
    "# get AUCPR\n",
    "auc_pr = average_precision_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'micro')\n",
    "\n",
    "# get F1 score\n",
    "f1 = f1_score(list_truth_labels_one_hot, list_predictions_one_hot, average = 'micro')\n",
    "\n",
    "# get MCC\n",
    "mcc = matthews_corrcoef(list_truth_labels, list_predictions)\n",
    "\n",
    "# get ARI\n",
    "ari = adjusted_rand_score(list_truth_labels, list_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cdc55189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_macro:  0.9550681528909919\n",
      "auc_micro:  0.9689698492462311\n",
      "auc_pr:  0.9544176441251484\n",
      "f1:  0.9689698492462312\n",
      "MCC:  0.9035755776808341\n",
      "ARI:  0.8621752054827151\n"
     ]
    }
   ],
   "source": [
    "print(\"auc_macro: \", auc_macro)\n",
    "print(\"auc_micro: \", auc_micro)\n",
    "print(\"auc_pr: \", auc_pr)\n",
    "print(\"f1: \", f1)\n",
    "print(\"MCC: \", mcc)\n",
    "print(\"ARI: \", ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42912e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
